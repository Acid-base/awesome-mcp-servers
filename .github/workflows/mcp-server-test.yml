---
name: MCP Server Awesome List Tests (Parallel Matrix)
on:
  workflow_dispatch:
    inputs:
      timeout_minutes:
        description: Timeout in minutes for EACH server test job
        type: string
        default: "60"
      max_servers:
        description: Maximum number of servers to test (0 for all)
        type: string
        default: "256"
  schedule:
    - cron: 0 5 * * 1
env:
  NODE_VERSION: 20
  GO_VERSION: 1.22.2
jobs:
  prepare-server-list:
    name: Prepare Server List for Matrix
    runs-on: ubuntu-latest
    outputs:
      server_list_json: ${{ steps.fetch.outputs.server_list_json }}
      repo_count: ${{ steps.fetch.outputs.count }}
    steps:
      - name: Fetch, Parse, and Prepare Server List JSON
        id: fetch
        shell: bash
        run: >
          echo "Checking out fork to get server list..."

          # Use sparse checkout to only get the README

          git clone --depth 1 --filter=blob:none --sparse https://github.com/Acid-base/awesome-mcp-servers.git awesome-list-fork

          cd awesome-list-fork

          # Configure sparse checkout to only include README.md at the root

          git sparse-checkout init --cone

          git sparse-checkout set README.md

          # REMOVED: git checkout # This line was likely causing the error


          echo "Parsing README.md..."

          # Check if README.md exists in the sparse working directory

          if [ ! -f README.md ]; then
             echo "::error::README.md not found after sparse checkout set."
             exit 1
          fi

          # Process the README.md file

          awk '/^## Server Implementations/{flag=1; next} /^## Frameworks/{flag=0} flag' README.md | \
            grep -oE 'https?:\/\/(github\.com|gitlab\.com|gitea\.com)\/[^/]+\/[^)/ ]+' | \
            sed -E 's/^https?:\/\///' | \
            sed 's/\.git$//' | \
            sort -u > ../repo_list_full.txt

          # Rest of the script remains the same...

          REPO_COUNT_FULL=$(wc -l < ../repo_list_full.txt || echo 0)

          echo "Found $REPO_COUNT_FULL potential servers."


          MAX_SERVERS=$((${{ github.event.inputs.max_servers || 0 }}))

          if [[ "$MAX_SERVERS" -gt 0 && "$MAX_SERVERS" -lt "$REPO_COUNT_FULL" ]]; then
            echo "Limiting to first $MAX_SERVERS servers from the list."
            head -n "$MAX_SERVERS" ../repo_list_full.txt > ../repo_list.txt
            REPO_COUNT=$(wc -l < ../repo_list.txt || echo 0)
            echo "Testing limited count: $REPO_COUNT servers."
          else
            cp ../repo_list_full.txt ../repo_list.txt
            REPO_COUNT="$REPO_COUNT_FULL"
            echo "Testing full count: $REPO_COUNT servers."
          fi


          if [ ! -s ../repo_list.txt ]; then
             REPO_COUNT=0
          fi


          if [ "$REPO_COUNT" -eq 0 ]; then
            echo "::warning::No server implementations found or list is empty after limit."
            echo "count=0" >> $GITHUB_OUTPUT
            echo "server_list_json='[]'" >> $GITHUB_OUTPUT
          else
            echo "Final Server List (repo_list.txt):"
            cat ../repo_list.txt
            SERVER_JSON=$(jq --raw-input --slurp 'split("\n") | map(select(length > 0))' < ../repo_list.txt)
            echo "count=$REPO_COUNT" >> $GITHUB_OUTPUT
            echo "server_list_json<<EOF" >> $GITHUB_OUTPUT
            echo "$SERVER_JSON" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            echo "Generated JSON: $SERVER_JSON"
          fi


          cd ..

          rm -rf awesome-list-fork

          rm -f ../repo_list_full.txt
      - name: Upload Server List Text File (Optional)
        if: steps.fetch.outputs.repo_count > 0
        uses: actions/upload-artifact@v4
        with:
          name: repo-list-text-${{ github.run_id }}
          path: repo_list.txt
          if-no-files-found: warn
  test-server:
    name: Test ${{ matrix.server_repo }}
    needs: prepare-server-list
    if: needs.prepare-server-list.outputs.repo_count > 0
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      fail-fast: false
      matrix:
        server_repo: ${{ fromJson(needs.prepare-server-list.outputs.server_list_json) }}
    steps:
      - name: Setup Tool Versions Cache
        id: tool-versions
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            ~/.cargo/bin # Cache the whole bin dir for uv/etc.
            ~/.deno
          key: ${{ runner.os }}-usertools-${{ hashFiles('**/package-lock.json',
            '**/go.sum', '**/requirements*.txt', '**/pyproject.toml',
            '**/uv.lock') }}-${{ env.NODE_VERSION }}-${{ env.GO_VERSION
            }}-deno-v1
          restore-keys: |
            ${{ runner.os }}-usertools-
      - name: Setup Prerequisites
        shell: bash
        run: >
          echo "Setting up tools and dependencies for ${{ matrix.server_repo }}..."

          # Base packages installation

          if ! command -v jq &> /dev/null || ! command -v git &> /dev/null; then echo "Installing base packages (jq, git)..."; sudo apt-get update && sudo apt-get install -y --no-install-recommends jq git coreutils ca-certificates curl gnupg; else echo "Base packages likely already present."; fi


          # Node.js Setup (Installs if not present, relies on runner's cached node if possible)

          echo "Setting up Node.js v${{ env.NODE_VERSION }}..."

          # Use setup-node action for robust installation/caching

          # actions/setup-node might be better, but stick to manual for now if preferred

          node_path=$(find /opt/hostedtoolcache/node -maxdepth 1 -name "${{ env.NODE_VERSION }}.*" 2>/dev/null | head -n 1); if [ -z "$node_path" ]; then echo "Node.js not found in runner cache, installing system version..."; curl -fsSL https://deb.nodesource.com/setup_${{ env.NODE_VERSION }}.x | sudo -E bash -; sudo apt-get install -y nodejs; else echo "Node.js found in runner cache."; echo "$node_path/bin" >> $GITHUB_PATH; fi; echo "Node Version: $(node --version)"; echo "NPM Version: $(npm --version)"


          # uv Setup (Checks cache path first, then installs)

          if ! command -v uv &> /dev/null; then echo "Setting up uv..."; curl -LsSf https://astral.sh/uv/install.sh | sh; fi; echo "$HOME/.cargo/bin" >> $GITHUB_PATH; echo "uv Version: $(uv --version || echo 'not found')"


          # Go Setup (Installs if not present)

          if ! command -v go &> /dev/null || ! go version | grep -q "go${{ env.GO_VERSION }}"; then echo "Setting up Go v${{ env.GO_VERSION }}..."; curl -fsSL "https://golang.org/dl/go${{ env.GO_VERSION }}.linux-amd64.tar.gz" -o go.tar.gz; sudo rm -rf /usr/local/go && sudo tar -C /usr/local -xzf go.tar.gz; rm go.tar.gz; fi; echo "/usr/local/go/bin" >> $GITHUB_PATH; echo "Go Version: $(go version)"


          # Deno Setup (Checks cache path first, then installs)

          if ! command -v deno &> /dev/null; then echo "Setting up Deno..."; curl -fsSL https://deno.land/install.sh | sh; fi; echo "$HOME/.deno/bin" >> $GITHUB_PATH; echo "Deno Version: $(deno --version || echo 'not found')"


          # Verify Docker

          echo "Verifying Docker..."; docker --version; echo "Prerequisites setup complete."
      - name: Test Server ${{ matrix.server_repo }}
        id: test-server-step
        env:
          GH_MCP_TOKEN: ${{ secrets.MCP_TESTER_GITHUB_PAT }}
        shell: bash
        run: >
          REPO="${{ matrix.server_repo }}"

          RESULTS_DIR="${GITHUB_WORKSPACE}/individual-results"

          mkdir -p "$RESULTS_DIR"


          echo ""; echo "======================================================================"

          echo "Starting Test for Repo: ${REPO}"; echo "======================================================================"; echo ""


          CHECKOUT_DIR="${GITHUB_WORKSPACE}/mcp_server_under_test"

          REPO_SLUG=$(echo "$REPO" | tr '/' '_' | tr '.' '_' | tr -cd '[:alnum:]_-' | cut -c1-60)

          echo "repo_slug_generated=$REPO_SLUG" >> $GITHUB_OUTPUT # Use standard GITHUB_OUTPUT

          echo "REPO_SLUG for this job: $REPO_SLUG"


          RESULT_JSON_FILE="${RESULTS_DIR}/${REPO_SLUG}_result.json"

          STATUS="SKIPPED"; REASON="Test logic did not complete"; RUN_METHOD="None"

          TEST_START_TIME=$(date +%s); CHECKOUT_PATH="$CHECKOUT_DIR"


          record_result() {
            local status="$1"; local reason="$2"; local method="$3"; local duration=$(($(date +%s) - TEST_START_TIME))
            jq -nc --arg repo "$REPO" --arg status "$status" --arg reason "$reason" --arg method "$method" --argjson duration "$duration" \
              '{repo: $repo, status: $status, reason: $reason, method: $method, duration: $duration}' > "$RESULT_JSON_FILE"
            local ANNOTATION_REASON=$(echo "$reason" | sed 's/%/%25/g; s/\r/%0D/g; s/\n/%0A/g')
            echo ""; echo "--- Test Result :: ${REPO} ---"; echo "- Run Method Attempted: ${method}"; echo "- Outcome: ${status}"; echo "- Details: ${reason}"; echo "- Duration: ${duration}s"; echo "--------------------------------------------------"; echo ""
            if [[ "$status" == "FAILURE" ]]; then echo "::error title=Test Failed ${REPO}::Repo=${REPO}, Status=${status}, Method=${method}, Reason=${ANNOTATION_REASON}"
            elif [[ "$status" == "SKIPPED" ]]; then echo "::warning title=Test Skipped ${REPO}::Repo=${REPO}, Status=${status}, Method=${method}, Reason=${ANNOTATION_REASON}"
            else echo "::notice title=Test Passed ${REPO}::Repo=${REPO}, Status=${status}, Method=${method}, Reason=${ANNOTATION_REASON}"
            fi
          }


          echo "--> Checking out $REPO into $CHECKOUT_PATH..."

          rm -rf "$CHECKOUT_PATH"; GIT_CLONE_URL=""; if [[ "$REPO" == github.com/* || "$REPO" == gitlab.com/* || "$REPO" == gitea.com/* ]]; then GIT_CLONE_URL="https://${REPO}.git"; else GIT_CLONE_URL="https://github.com/${REPO}.git"; fi

          echo "--> Cloning URL: $GIT_CLONE_URL"

          if ! timeout 300s git clone --depth 1 "$GIT_CLONE_URL" "$CHECKOUT_PATH"; then record_result "SKIPPED" "Checkout failed. URL: $GIT_CLONE_URL" "None"; exit 0; fi

          if [ ! -d "$CHECKOUT_PATH" ] || [ -z "$(ls -A "$CHECKOUT_PATH")" ]; then record_result "SKIPPED" "Checkout empty. URL: $GIT_CLONE_URL" "None"; exit 0; fi

          echo "--> Checkout successful."


          TEMP_RESULT_FILE=$(mktemp); TEMP_LOG_FILE=$(mktemp)


          ( # Start subshell for isolation
            cd "$CHECKOUT_PATH" || exit 1; set -e
            SUB_STATUS="SKIPPED"; SUB_REASON="No method matched"; SUB_RUN_METHOD="None"

            # --- Use the corrected cleanup_subshell ---
            cleanup_subshell() {
              echo "SUB_STATUS='${SUB_STATUS}'" > "$TEMP_RESULT_FILE"
              local escaped_reason=$(echo "${SUB_REASON}" | sed "s/'/'\\\\''/g")
              echo "SUB_REASON='${escaped_reason}'" >> "$TEMP_RESULT_FILE"
              echo "SUB_RUN_METHOD='${SUB_RUN_METHOD}'" >> "$TEMP_RESULT_FILE"
            }
            trap cleanup_subshell EXIT
            # --- End corrected cleanup_subshell ---

            # Helper Functions (same as before)
            run_inspector_test() { local SERVER_TARGET="$1"; local METHOD_NAME="$2"; local TEST_TYPE="${3:-stdio}"; echo "--> Testing: $METHOD_NAME ($TEST_TYPE) target: $SERVER_TARGET"; local INSPECTOR_CMD=""; if [[ "$TEST_TYPE" == "stdio" ]]; then INSPECTOR_CMD="npx --yes @modelcontextprotocol/inspector --cli \"$SERVER_TARGET\" --method tools/list"; elif [[ "$TEST_TYPE" == "sse" ]]; then INSPECTOR_CMD="npx --yes @modelcontextprotocol/inspector --sse $SERVER_TARGET --method tools/list"; else echo "::error::Unknown test type '$TEST_TYPE'"; return 1; fi; echo "----> Running Inspector: $INSPECTOR_CMD"; if timeout 180s $INSPECTOR_CMD; then echo "----> Inspector SUCCESS"; SUB_STATUS="SUCCESS"; SUB_REASON="Tested via $METHOD_NAME ($TEST_TYPE)"; SUB_RUN_METHOD="$METHOD_NAME"; return 0; else local ec=$?; echo "----> Inspector FAILURE (EC: $ec)"; SUB_STATUS="FAILURE"; SUB_REASON="Inspector failed (EC: $ec) for $METHOD_NAME ($TEST_TYPE)"; SUB_RUN_METHOD="$METHOD_NAME"; return 1; fi; }
            run_docker_container() { local IMAGE_TAG="$1"; local CONTAINER_NAME="$2"; local CONTAINER_PORT_INTERNAL="${3:-8080}"; local CONTAINER_PORT_FALLBACK="${4:-6277}"; echo "--> Starting container $CONTAINER_NAME ($IMAGE_TAG) exposing internal port $CONTAINER_PORT_INTERNAL (fallback $CONTAINER_PORT_FALLBACK)..."; if ! docker run -d --rm --name "$CONTAINER_NAME" -P "$IMAGE_TAG"; then echo "::error::Failed to start container $IMAGE_TAG"; return 1; fi; echo "--> Container starting. Waiting 20s for stabilization..."; sleep 20; if ! docker ps --filter "name=$CONTAINER_NAME" --filter "status=running" | grep -q "$CONTAINER_NAME"; then echo "::error::Container $CONTAINER_NAME started but exited prematurely."; cleanup_docker "$CONTAINER_NAME"; return 1; fi; HOST_PORT=$(docker port "$CONTAINER_NAME" "$CONTAINER_PORT_INTERNAL/tcp" 2>/dev/null | sed 's/.*://'); if [ -z "$HOST_PORT" ]; then echo "--> Port $CONTAINER_PORT_INTERNAL not mapped? Trying fallback $CONTAINER_PORT_FALLBACK..."; HOST_PORT=$(docker port "$CONTAINER_NAME" "$CONTAINER_PORT_FALLBACK/tcp" 2>/dev/null | sed 's/.*://'); fi; if [ -z "$HOST_PORT" ]; then echo "::error::Could not find mapped host port for $CONTAINER_PORT_INTERNAL or $CONTAINER_PORT_FALLBACK on container $CONTAINER_NAME."; cleanup_docker "$CONTAINER_NAME"; return 1; fi; echo "--> Container $CONTAINER_NAME ready. Mapped Host Port: $HOST_PORT"; export FOUND_HOST_PORT="$HOST_PORT"; return 0; }
            cleanup_docker() { local CONTAINER_NAME="$1"; echo "--> Cleaning up Docker container $CONTAINER_NAME..."; timeout 30s docker stop "$CONTAINER_NAME" > /dev/null 2>&1 || true; timeout 30s docker rm "$CONTAINER_NAME" > /dev/null 2>&1 || true; }

            # Detection Logic (same as before)
            echo "--- Detecting Run Method ---"; NORMALIZED_REPO_NAME=$(echo "$REPO" | sed -E 's/^(github\.com|gitlab\.com|gitea\.com)\///' | sed 's/\.git$//');
            if [[ "$NORMALIZED_REPO_NAME" == "github/github-mcp-server" ]]; then METHOD="Docker Image (Official GitHub)"; if [ -z "$GH_MCP_TOKEN" ]; then SUB_STATUS="SKIPPED"; SUB_REASON="Required secret: GH_MCP_TOKEN"; else SERVER_CMD="docker run -i --rm -e GITHUB_PERSONAL_ACCESS_TOKEN=$GH_MCP_TOKEN ghcr.io/github/github-mcp-server"; run_inspector_test "$SERVER_CMD" "$METHOD"; fi
            elif [[ "$NORMALIZED_REPO_NAME" == "microsoft/playwright-mcp" ]]; then METHOD="npx @playwright/mcp"; SERVER_CMD="npx --yes @playwright/mcp@latest --headless"; run_inspector_test "$SERVER_CMD" "$METHOD"
            elif [[ "$NORMALIZED_REPO_NAME" == "pydantic/pydantic-ai" ]]; then METHOD="deno run jsr:"; (cd "${GITHUB_WORKSPACE}" && timeout 120s deno run -A --node-modules-dir=auto jsr:@pydantic/mcp-run-python warmup) || { SUB_STATUS="FAILURE"; SUB_REASON="Deno warmup failed jsr:@pydantic/mcp-run-python"; exit 1; }; SERVER_CMD="deno run -A --node-modules-dir=auto jsr:@pydantic/mcp-run-python stdio"; run_inspector_test "$SERVER_CMD" "$METHOD"
            elif [ -f "docker-compose.yml" ] || [ -f "compose.yml" ]; then METHOD="Docker Compose (Detected)"; if [ -f "Dockerfile" ]; then METHOD="Dockerfile (Compose Fallback)"; IMAGE="mcp-test-image-${REPO_SLUG}"; CONTAINER="mcp-server-test-${REPO_SLUG}"; if timeout 300s docker build -t "$IMAGE" .; then if run_docker_container "$IMAGE" "$CONTAINER"; then run_inspector_test "http://localhost:${FOUND_HOST_PORT}/sse" "$METHOD" "sse"; cleanup_docker "$CONTAINER"; else SUB_STATUS="FAILURE"; SUB_REASON="Container start/run failed"; cleanup_docker "$CONTAINER"; fi; else SUB_STATUS="SKIPPED"; SUB_REASON="docker build failed"; fi; else SUB_STATUS="SKIPPED"; SUB_REASON="docker-compose.yml found but no Dockerfile present"; fi
            elif [ -f "Dockerfile" ]; then METHOD="Dockerfile"; IMAGE="mcp-test-image-${REPO_SLUG}"; CONTAINER="mcp-server-test-${REPO_SLUG}"; if timeout 300s docker build -t "$IMAGE" .; then if run_docker_container "$IMAGE" "$CONTAINER"; then run_inspector_test "http://localhost:${FOUND_HOST_PORT}/sse" "$METHOD" "sse"; cleanup_docker "$CONTAINER"; else SUB_STATUS="FAILURE"; SUB_REASON="Container start/run failed"; cleanup_docker "$CONTAINER"; fi; else SUB_STATUS="SKIPPED"; SUB_REASON="docker build failed"; fi
            elif [ -f "package.json" ]; then METHOD="Node.js"; INSTALL_CMD="npm install"; if [ -f "package-lock.json" ] || [ -f "npm-shrinkwrap.json" ]; then INSTALL_CMD="npm ci"; fi; if timeout 300s $INSTALL_CMD --no-audit --no-fund --loglevel=error; then INSPECTOR_EXIT_CODE=1; if node -e "process.exit(require('./package.json').scripts?.start ? 0 : 1)" 2>/dev/null && run_inspector_test "npm start" "$METHOD"; then INSPECTOR_EXIT_CODE=0; fi; if [ $INSPECTOR_EXIT_CODE -ne 0 ]; then MAIN_ENTRY=$(node -p "try{require('./package.json').main||'index.js'}catch(e){'index.js'}" 2>/dev/null); if [ -n "$MAIN_ENTRY" ] && { [ -f "$MAIN_ENTRY" ] || [ -f "${MAIN_ENTRY}.js" ] || [ -d "$MAIN_ENTRY" ]; } && run_inspector_test "node ." "$METHOD"; then INSPECTOR_EXIT_CODE=0; fi; fi; if [ $INSPECTOR_EXIT_CODE -ne 0 ]; then if node -e "try{const p=require('./package.json');const isHttp=(p.scripts?.start&&!p.scripts.start.includes('stdio'))||(p.main&&!p.main.includes('stdio'));process.exit(isHttp?0:1)}catch(e){process.exit(1)}" 2>/dev/null; then SUB_STATUS="SKIPPED"; SUB_REASON="stdio test failed; package.json suggests HTTP server"; else SUB_STATUS="FAILURE"; SUB_REASON="Inspector test failed for 'npm start' and 'node .'"; fi; fi; else SUB_STATUS="SKIPPED"; SUB_REASON="npm install/ci failed"; fi
            elif [ -f "pyproject.toml" ] || [ -f "requirements.txt" ]; then METHOD="Python"; if uv venv .venv --seed; then source .venv/bin/activate || { SUB_STATUS="SKIPPED"; SUB_REASON="venv activation failed"; exit 0; }; INSTALL_CMD="uv sync"; if [ -f "pyproject.toml" ] && grep -qE '^\[project\]' pyproject.toml; then INSTALL_CMD='uv pip install ".[all]" || uv pip install "."'; elif [ -f "requirements.lock" ] || [ -f "uv.lock" ]; then INSTALL_CMD="uv sync --locked"; elif [ -f "requirements.txt" ]; then INSTALL_CMD="uv pip install -r requirements.txt"; fi; if timeout 300s $INSTALL_CMD; then INSPECTOR_EXIT_CODE=1; if [ -f "main.py" ] && run_inspector_test "python main.py" "$METHOD"; then INSPECTOR_EXIT_CODE=0; fi; if [ $INSPECTOR_EXIT_CODE -ne 0 ] && [ -f "app.py" ] && run_inspector_test "python app.py" "$METHOD"; then INSPECTOR_EXIT_CODE=0; fi; if [ $INSPECTOR_EXIT_CODE -ne 0 ] && [ -f "server.py" ] && run_inspector_test "python server.py" "$METHOD"; then INSPECTOR_EXIT_CODE=0; fi; if [ $INSPECTOR_EXIT_CODE -ne 0 ]; then PY_MOD_NAME=$(basename "$PWD" | sed 's/-/_/g'); if { [ -d "$PY_MOD_NAME" ] || [ -f "${PY_MOD_NAME}.py" ]; } && run_inspector_test "python -m $PY_MOD_NAME" "$METHOD"; then INSPECTOR_EXIT_CODE=0; fi; fi; if [ $INSPECTOR_EXIT_CODE -ne 0 ]; then SUB_STATUS="FAILURE"; SUB_REASON="Inspector test failed for common Python entry points"; fi; else SUB_STATUS="SKIPPED"; SUB_REASON="uv sync/install failed"; fi; deactivate || true; else SUB_STATUS="SKIPPED"; SUB_REASON="uv venv failed"; fi
            elif [ -f "go.mod" ]; then METHOD="Go (go.mod)"; BINARY_NAME="mcp-server-go-binary"; if timeout 300s go build -o "$BINARY_NAME" .; then if [ -f "$BINARY_NAME" ]; then INSPECTOR_EXIT_CODE=1; if run_inspector_test "./$BINARY_NAME stdio" "$METHOD"; then INSPECTOR_EXIT_CODE=0; fi; if [ $INSPECTOR_EXIT_CODE -ne 0 ] && run_inspector_test "./$BINARY_NAME" "$METHOD"; then INSPECTOR_EXIT_CODE=0; fi; if [ $INSPECTOR_EXIT_CODE -ne 0 ]; then SUB_STATUS="FAILURE"; SUB_REASON="Inspector test failed for Go binary (tried with and without 'stdio' arg)"; fi; else SUB_STATUS="FAILURE"; SUB_REASON="go build succeeded but output binary '$BINARY_NAME' not found"; fi; else SUB_STATUS="SKIPPED"; SUB_REASON="go build failed"; fi
            else SUB_RUN_METHOD="None"; SUB_STATUS="SKIPPED"; SUB_REASON="No known build/package config found (Dockerfile, package.json, pyproject.toml, requirements.txt, go.mod)"; fi
            echo "--- Subshell test logic complete ---"

          ) > "$TEMP_LOG_FILE" 2>&1

          SUBSHELL_EXIT_CODE=$?


          # Process Subshell Results

          echo "--> Subshell exited with code: $SUBSHELL_EXIT_CODE for ${REPO}"

          if [ -f "$TEMP_RESULT_FILE" ]; then
            source "$TEMP_RESULT_FILE" # Source the quoted assignments
            STATUS=${SUB_STATUS:-FAILURE}; REASON=${SUB_REASON:-"Result parsing error after source"}; RUN_METHOD=${SUB_RUN_METHOD:-Unknown};
            if [[ $SUBSHELL_EXIT_CODE -ne 0 && "$STATUS" == "SUCCESS" ]]; then STATUS="FAILURE"; REASON="Success reported but subshell exited non-zero (EC: $SUBSHELL_EXIT_CODE). Original Reason: $REASON"; fi;
            if [[ $SUBSHELL_EXIT_CODE -ne 0 && "$STATUS" == "SKIPPED" ]]; then STATUS="FAILURE"; REASON="Skipped reported but subshell exited non-zero (EC: $SUBSHELL_EXIT_CODE). Original Reason: $REASON"; fi;
          else
            echo "::error:: Subshell result file missing for ${REPO}!"; STATUS="FAILURE"; REASON="Subshell failed catastrophically (EC: $SUBSHELL_EXIT_CODE, result file missing)."; RUN_METHOD="Unknown";
          fi

          if [[ "$STATUS" != "SUCCESS" ]]; then echo "--- Subshell Log for ${REPO} ---"; cat "$TEMP_LOG_FILE" || echo "Log read error."; echo "--- End Subshell Log ---"; fi


          record_result "$STATUS" "$REASON" "$RUN_METHOD"


          # Cleanup

          echo "--> Cleaning up checkout directory ${CHECKOUT_PATH} and temp files for ${REPO}..."

          rm -rf "$CHECKOUT_PATH" "$TEMP_LOG_FILE" "$TEMP_RESULT_FILE"
      - name: Upload Individual Result
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: result-${{ steps.test-server-step.outputs.repo_slug_generated }}-${{
            github.run_id }}
          path: ${{ github.workspace }}/individual-results/${{
            steps.test-server-step.outputs.repo_slug_generated }}_result.json
          retention-days: 5
          if-no-files-found: warn
  summarize-results:
    name: Summarize Test Results
    needs:
      - prepare-server-list
      - test-server
    runs-on: ubuntu-latest
    if: always() && needs.prepare-server-list.outputs.repo_count > 0
    steps:
      - name: Download All Individual Results
        uses: actions/download-artifact@v4
        with:
          pattern: result-*-${{ github.run_id }}
          path: downloaded-results
        continue-on-error: true
      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq
      - name: Generate Final Summary Report
        id: summary
        shell: bash
        run: >
          RESULTS_DIR="downloaded-results"

          SUMMARY_FILE="test_summary.md"

          JSON_SUMMARY_FILE="test_summary.json"


          echo "Checking for downloaded test results in $RESULTS_DIR..."

          json_files=$(find "$RESULTS_DIR" -name '*.json')

          if [ -z "$json_files" ]; then
            echo "::warning::No individual test result JSON files found under $RESULTS_DIR (or download failed)."
            SUMMARY_CONTENT="### Test Summary\n\nNo test results were found to summarize. This could happen if all test jobs failed before producing results or if the artifact download failed."; echo -e "$SUMMARY_CONTENT" > "$SUMMARY_FILE"; echo -e "$SUMMARY_CONTENT" >> "$GITHUB_STEP_SUMMARY"; echo "[]" > "$JSON_SUMMARY_FILE"; echo "failure_count=0" >> "$GITHUB_OUTPUT"; echo "summary_status=No Results" >> "$GITHUB_OUTPUT"; exit 0
          fi


          echo "Combining JSON files from $RESULTS_DIR..."

          if ! find "$RESULTS_DIR" -name '*.json' -print0 | xargs -0 jq --slurp 'flatten | map(select(. != null))' > "$JSON_SUMMARY_FILE"; then
             echo "::error::Failed to combine JSON results using find/xargs/jq. Check files in '$RESULTS_DIR'."
             SUMMARY_CONTENT="### Test Summary\n\nError combining test results."; echo -e "$SUMMARY_CONTENT" > "$SUMMARY_FILE"; echo -e "$SUMMARY_CONTENT" >> "$GITHUB_STEP_SUMMARY"; echo "[]" > "$JSON_SUMMARY_FILE"; echo "failure_count=1" >> "$GITHUB_OUTPUT"; echo "summary_status=Error" >> "$GITHUB_OUTPUT"; exit 1
          fi


          if [ ! -s "$JSON_SUMMARY_FILE" ] || [ "$(jq 'length' "$JSON_SUMMARY_FILE" 2>/dev/null)" == "0" ]; then
             echo "::warning::Combined results file is empty or contains no valid JSON objects after processing '$RESULTS_DIR'."
             SUMMARY_CONTENT="### Test Summary\n\nNo valid test results found after combining."; echo -e "$SUMMARY_CONTENT" > "$SUMMARY_FILE"; echo -e "$SUMMARY_CONTENT" >> "$GITHUB_STEP_SUMMARY"; echo "[]" > "$JSON_SUMMARY_FILE"; echo "failure_count=0" >> "$GITHUB_OUTPUT"; echo "summary_status=No Valid Results" >> "$GITHUB_OUTPUT"; exit 0
          fi


          echo "Calculating summary counts..."

          SUCCESS_COUNT=$(jq '[.[] | select(.status=="SUCCESS")] | length' "$JSON_SUMMARY_FILE") || { echo "::error::jq failed calculating SUCCESS"; exit 1; }

          FAILURE_COUNT=$(jq '[.[] | select(.status=="FAILURE")] | length' "$JSON_SUMMARY_FILE") || { echo "::error::jq failed calculating FAILURE"; exit 1; }

          SKIPPED_COUNT=$(jq '[.[] | select(.status=="SKIPPED")] | length' "$JSON_SUMMARY_FILE") || { echo "::error::jq failed calculating SKIPPED"; exit 1; }

          TOTAL_COUNT=$(jq 'length' "$JSON_SUMMARY_FILE") || { echo "::error::jq failed calculating TOTAL"; exit 1; }

          echo "Summary Counts: Total=$TOTAL_COUNT, Success=$SUCCESS_COUNT, Failure=$FAILURE_COUNT, Skipped=$SKIPPED_COUNT"


          echo "failure_count=$FAILURE_COUNT" >> "$GITHUB_OUTPUT"

          OVERALL_STATUS="Success"; if [[ "$FAILURE_COUNT" -gt 0 ]]; then OVERALL_STATUS="Failure"; fi

          echo "summary_status=$OVERALL_STATUS" >> "$GITHUB_OUTPUT"


          # Generate Markdown Report (same as before)

          echo "Generating full Markdown summary report ($SUMMARY_FILE)..."

          { echo "# Test Summary Report"; echo; echo "**Overall Status: $OVERALL_STATUS**"; echo; printf -- "- Total Processed: %s\n" "$TOTAL_COUNT"; printf -- "- ✅ Success: %s\n" "$SUCCESS_COUNT"; printf -- "- ❌ Failure: %s\n" "$FAILURE_COUNT"; printf -- "- ⚠️ Skipped: %s\n" "$SKIPPED_COUNT"; echo; echo "## Failures ($FAILURE_COUNT)"; echo; if [ "$FAILURE_COUNT" -gt 0 ]; then echo "| Repository | Method | Reason | Duration (s) |"; echo "|---|---|---|---|"; jq -r '.[] | select(.status=="FAILURE") | "| `\(.repo // "-")` | `\(.method // "-")` | \(.reason // "-" | gsub("\\|"; "\\\\|") | gsub("\r?\n"; "<br>")) | \(.duration // "-") |"' "$JSON_SUMMARY_FILE" || echo "| Error generating failure table | | | |"; else echo "_None_"; fi; echo; echo "## Skipped ($SKIPPED_COUNT)"; echo; if [ "$SKIPPED_COUNT" -gt 0 ]; then echo "| Repository | Method | Reason | Duration (s) |"; echo "|---|---|---|---|"; jq -r '.[] | select(.status=="SKIPPED") | "| `\(.repo // "-")` | `\(.method // "-")` | \(.reason // "-" | gsub("\\|"; "\\\\|") | gsub("\r?\n"; "<br>")) | \(.duration // "-") |"' "$JSON_SUMMARY_FILE" || echo "| Error generating skipped table | | | |"; else echo "_None_"; fi; echo; } > "$SUMMARY_FILE"

          echo "Full report generated: $SUMMARY_FILE"


          # Generate GitHub Step Summary (same as before)

          echo "Generating concise summary for GitHub Step Summary..."

          { echo "### Test Summary"; echo; echo "**Overall Status: $OVERALL_STATUS**"; echo "- ✅ Success: $SUCCESS_COUNT"; echo "- ❌ Failure: $FAILURE_COUNT"; echo "- ⚠️ Skipped: $SKIPPED_COUNT"; echo "- Total Processed: $TOTAL_COUNT"; if [[ "$FAILURE_COUNT" -gt 0 || "$SKIPPED_COUNT" -gt 0 ]]; then echo ""; echo "*See 'test-summary-report' artifact for full details.*"; fi; } >> "$GITHUB_STEP_SUMMARY"

          echo "GitHub Step Summary updated."
      - name: Upload Final Summary Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: test-summary-report-${{ github.run_id }}
          path: |
            test_summary.md
            test_summary.json
          if-no-files-found: error
      - name: Check for Failures in Summary and Fail Workflow
        run: >
          FAILURE_COUNT="${{ steps.summary.outputs.failure_count || '0' }}"

          SUMMARY_STATUS="${{ steps.summary.outputs.summary_status || 'Unknown' }}"

          echo "Checking final summary: Status='$SUMMARY_STATUS', Failures=$FAILURE_COUNT"

          if [[ "$FAILURE_COUNT" -gt 0 ]]; then echo "::error::Detected $FAILURE_COUNT test failure(s) in the summary. Failing workflow."; exit 1; fi

          if [[ "$SUMMARY_STATUS" == "Error" ]]; then echo "::error::Summary generation failed. Failing workflow."; exit 1; fi

          if [[ "$SUMMARY_STATUS" == "No Results" ]] || [[ "$SUMMARY_STATUS" == "No Valid Results" ]]; then echo "::warning::No test results were generated or summarized."; exit 0; fi

          echo "Workflow finished successfully with $SUMMARY_STATUS status and $FAILURE_COUNT failures."
